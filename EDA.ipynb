{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8DVqYCwtdPN"
   },
   "source": [
    "# Fake News Detection Dataset - Exploratory Data Analysis\n",
    "\n",
    "This notebook performs comprehensive EDA on the ISOT Fake News Dataset to understand patterns that distinguish fake news from authentic journalism.\n",
    "\n",
    "**Dataset:** ISOT Fake News Dataset from Kaggle\n",
    "**Goal:** Identify linguistic and structural patterns for fake news classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10117,
     "status": "ok",
     "timestamp": 1764462780679,
     "user": {
      "displayName": "Ledja Halltari",
      "userId": "02609488241572809833"
     },
     "user_tz": 480
    },
    "id": "-g-7TPK3ul-1",
    "outputId": "22af5f4f-7dda-4237-9300-60f5898993ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textstat in /usr/local/lib/python3.12/dist-packages (0.7.11)\n",
      "Requirement already satisfied: pyphen in /usr/local/lib/python3.12/dist-packages (from textstat) (0.17.2)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from textstat) (3.9.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from textstat) (75.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7212,
     "status": "ok",
     "timestamp": 1764462787900,
     "user": {
      "displayName": "Ledja Halltari",
      "userId": "02609488241572809833"
     },
     "user_tz": 480
    },
    "id": "5mlxGdgotdPO"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "from datetime import datetime\n",
    "from textstat import flesch_reading_ease, flesch_kincaid_grade\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmlhxxLStdPO"
   },
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "error",
     "timestamp": 1764462787974,
     "user": {
      "displayName": "Ledja Halltari",
      "userId": "02609488241572809833"
     },
     "user_tz": 480
    },
    "id": "JpH10E6VtdPP",
    "outputId": "1465ce30-8ae4-4d2b-f6d2-500f674641dc"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Fake.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3579769095.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Make sure to download the dataset from Kaggle and place the CSV files in the same directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfake_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fake.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrue_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'True.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Fake.csv'"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "# Make sure to download the dataset from Kaggle and place the CSV files in the same directory\n",
    "fake_df = pd.read_csv('News_dataset/Fake.csv')\n",
    "true_df = pd.read_csv('News_dataset/True.csv')\n",
    "\n",
    "# Add labels\n",
    "fake_df['label'] = 0  # 0 = Fake\n",
    "true_df['label'] = 1  # 1 = True\n",
    "\n",
    "# Combine datasets\n",
    "df = pd.concat([fake_df, true_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataset\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Total articles: {len(df):,}\")\n",
    "print(f\"Fake articles: {len(fake_df):,} ({len(fake_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"True articles: {len(true_df):,} ({len(true_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmB0wCEMtdPP"
   },
   "source": [
    "## 2. Data Quality Assessment and Missing Data Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1764462788012,
     "user": {
      "displayName": "Ledja Halltari",
      "userId": "02609488241572809833"
     },
     "user_tz": 480
    },
    "id": "JhXc8zdGtdPP"
   },
   "outputs": [],
   "source": [
    "# Data Quality Assessment\n",
    "print(\"\\n- Missing Values:\")\n",
    "missing_data = df.isnull().sum()\n",
    "print(missing_data)\n",
    "print(f\"\\nTotal missing values: {missing_data.sum()}\")\n",
    "\n",
    "print(\"\\n- Duplicate Records:\")\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Duplicate rows: {duplicates}\")\n",
    "\n",
    "print(\"\\n- Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n- Basic Statistics:\")\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17555,
     "status": "aborted",
     "timestamp": 1764462788012,
     "user": {
      "displayName": "Ledja Halltari",
      "userId": "02609488241572809833"
     },
     "user_tz": 480
    },
    "id": "9LWAuc0ntdPP"
   },
   "outputs": [],
   "source": [
    "# Check for empty or very short articles\n",
    "print(\"--- Content Quality Check ---\")\n",
    "\n",
    "# Text length analysis\n",
    "df['text_length'] = df['text'].str.len()\n",
    "df['title_length'] = df['title'].str.len()\n",
    "\n",
    "print(f\"Articles with empty text: {(df['text_length'] == 0).sum()}\")\n",
    "print(f\"Articles with very short text (<50 chars): {(df['text_length'] < 50).sum()}\")\n",
    "print(f\"Articles with empty titles: {(df['title_length'] == 0).sum()}\")\n",
    "\n",
    "# Subject distribution\n",
    "print(\"\\nSubject Distribution:\")\n",
    "subject_counts = df['subject'].value_counts()\n",
    "print(subject_counts)\n",
    "\n",
    "# Date format analysis\n",
    "print(\"\\nDate Format Sample:\")\n",
    "print(df['date'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fif7x_KtdPP"
   },
   "source": [
    "## 3. Descriptive Statistics and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17555,
     "status": "aborted",
     "timestamp": 1764462788012,
     "user": {
      "displayName": "Ledja Halltari",
      "userId": "02609488241572809833"
     },
     "user_tz": 480
    },
    "id": "rAjfHUf1tdPQ"
   },
   "outputs": [],
   "source": [
    "# Feature Engineering for Linguistic Analysis\n",
    "def extract_linguistic_features(text):\n",
    "    if pd.isna(text) or len(text) == 0:\n",
    "        return pd.Series([0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "    # Basic counts\n",
    "    text_length = len(text)\n",
    "    word_count = len(text.split())\n",
    "\n",
    "    # Punctuation analysis\n",
    "    exclamation_count = text.count('!')\n",
    "    question_count = text.count('?')\n",
    "\n",
    "    # Capitalization analysis\n",
    "    caps_count = sum(1 for c in text if c.isupper())\n",
    "    caps_ratio = caps_count / text_length if text_length > 0 else 0\n",
    "\n",
    "    # Ratios\n",
    "    exclamation_ratio = exclamation_count / word_count if word_count > 0 else 0\n",
    "    question_ratio = question_count / word_count if word_count > 0 else 0\n",
    "\n",
    "    return pd.Series([\n",
    "        text_length, word_count, exclamation_count, question_count,\n",
    "        caps_count, caps_ratio, exclamation_ratio, question_ratio\n",
    "    ])\n",
    "\n",
    "# Apply feature extraction\n",
    "print(\"Extracting linguistic features...\")\n",
    "\n",
    "# Extract features for text content\n",
    "text_features = df['text'].apply(extract_linguistic_features)\n",
    "text_features.columns = [\n",
    "    'text_length', 'text_word_count', 'text_exclamation_count', 'text_question_count',\n",
    "    'text_caps_count', 'text_caps_ratio', 'text_exclamation_ratio', 'text_question_ratio'\n",
    "]\n",
    "\n",
    "# Extract features for titles\n",
    "title_features = df['title'].apply(extract_linguistic_features)\n",
    "title_features.columns = [\n",
    "    'title_length', 'title_word_count', 'title_exclamation_count', 'title_question_count',\n",
    "    'title_caps_count', 'title_caps_ratio', 'title_exclamation_ratio', 'title_question_ratio'\n",
    "]\n",
    "\n",
    "# Combine features with original dataset\n",
    "df_features = pd.concat([df, text_features, title_features], axis=1)\n",
    "\n",
    "print(\"Feature extraction completed!\")\n",
    "print(f\"New dataset shape: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17555,
     "status": "aborted",
     "timestamp": 1764462788013,
     "user": {
      "displayName": "Ledja Halltari",
      "userId": "02609488241572809833"
     },
     "user_tz": 480
    },
    "id": "N9vWdB8qtdPQ"
   },
   "outputs": [],
   "source": [
    "# Descriptive Statistics by Class\n",
    "\n",
    "# Key features to analyze\n",
    "key_features = [\n",
    "    'text_length', 'text_word_count', 'title_length', 'title_word_count',\n",
    "    'text_caps_ratio', 'title_caps_ratio', 'text_exclamation_ratio', 'title_exclamation_ratio'\n",
    "]\n",
    "\n",
    "# Group by label and calculate statistics\n",
    "stats_by_class = df_features.groupby('label')[key_features].agg(['mean', 'std', 'median'])\n",
    "\n",
    "print(\"\\nStatistics by Class (0=Fake, 1=True):\")\n",
    "print(stats_by_class.round(3))\n",
    "\n",
    "# Create comparison table\n",
    "comparison_data = []\n",
    "for feature in key_features:\n",
    "    fake_mean = df_features[df_features['label'] == 0][feature].mean()\n",
    "    true_mean = df_features[df_features['label'] == 1][feature].mean()\n",
    "    fake_std = df_features[df_features['label'] == 0][feature].std()\n",
    "    true_std = df_features[df_features['label'] == 1][feature].std()\n",
    "\n",
    "    comparison_data.append({\n",
    "        'Feature': feature,\n",
    "        'Fake_Mean': fake_mean,\n",
    "        'Fake_Std': fake_std,\n",
    "        'True_Mean': true_mean,\n",
    "        'True_Std': true_std,\n",
    "        'Difference': abs(fake_mean - true_mean)\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nDetailed Feature Comparison:\")\n",
    "print(comparison_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztKcJZp9tdPQ"
   },
   "source": [
    "## 4. Distribution Plots and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17554,
     "status": "aborted",
     "timestamp": 1764462788013,
     "user": {
      "displayName": "Ledja Halltari",
      "userId": "02609488241572809833"
     },
     "user_tz": 480
    },
    "id": "2t2p7gG8tdPQ"
   },
   "outputs": [],
   "source": [
    "# ROBUST VERSION - This will definitely work\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Fake News Dataset - Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Data preparation with error checking\n",
    "print(\"Preparing data for plotting...\")\n",
    "fake_data = df_features[df_features['label'] == 0].copy()\n",
    "true_data = df_features[df_features['label'] == 1].copy()\n",
    "\n",
    "print(f\"Fake data shape: {fake_data.shape}\")\n",
    "print(f\"True data shape: {true_data.shape}\")\n",
    "\n",
    "# 1. Class Distribution\n",
    "ax1 = axes[0, 0]\n",
    "class_counts = df_features['label'].value_counts()\n",
    "wedges, texts, autotexts = ax1.pie(class_counts.values, labels=['Fake News', 'True News'],\n",
    "                                  autopct='%1.1f%%', colors=['#ff6b6b', '#4ecdc4'], startangle=90)\n",
    "ax1.set_title('Class Distribution', fontweight='bold')\n",
    "\n",
    "# 2. Text Length Distribution - Super safe version\n",
    "ax2 = axes[0, 1]\n",
    "try:\n",
    "    # Convert to numpy arrays and remove any NaN values\n",
    "    fake_text_len = fake_data['text_length'].dropna().values.flatten()\n",
    "    true_text_len = true_data['text_length'].dropna().values.flatten()\n",
    "\n",
    "    # Filter extreme values\n",
    "    fake_text_len = fake_text_len[fake_text_len < 15000]\n",
    "    true_text_len = true_text_len[true_text_len < 15000]\n",
    "\n",
    "    ax2.hist(fake_text_len, bins=50, alpha=0.7, density=True, label='Fake News', color='red')\n",
    "    ax2.hist(true_text_len, bins=50, alpha=0.7, density=True, label='True News', color='blue')\n",
    "    ax2.set_xlabel('Article Text Length (characters)')\n",
    "    ax2.set_ylabel('Density')\n",
    "    ax2.set_title('Text Length Distribution', fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.set_xlim(0, 10000)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in text length plot: {e}\")\n",
    "    ax2.text(0.5, 0.5, 'Text Length Distribution\\n(Error in data)',\n",
    "             ha='center', va='center', transform=ax2.transAxes)\n",
    "\n",
    "# 3. Title Length Distribution - Super safe version\n",
    "ax3 = axes[0, 2]\n",
    "try:\n",
    "    fake_title_len = fake_data['title_length'].dropna().values.flatten()\n",
    "    true_title_len = true_data['title_length'].dropna().values.flatten()\n",
    "\n",
    "    # Filter extreme values\n",
    "    fake_title_len = fake_title_len[fake_title_len < 500]\n",
    "    true_title_len = true_title_len[true_title_len < 500]\n",
    "\n",
    "    ax3.hist(fake_title_len, bins=30, alpha=0.7, density=True, label='Fake News', color='red')\n",
    "    ax3.hist(true_title_len, bins=30, alpha=0.7, density=True, label='True News', color='blue')\n",
    "    ax3.set_xlabel('Title Length (characters)')\n",
    "    ax3.set_ylabel('Density')\n",
    "    ax3.set_title('Title Length Distribution', fontweight='bold')\n",
    "    ax3.legend()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in title length plot: {e}\")\n",
    "    ax3.text(0.5, 0.5, 'Title Length Distribution\\n(Error in data)',\n",
    "             ha='center', va='center', transform=ax3.transAxes)\n",
    "\n",
    "# 4. Box Plot - Super safe version\n",
    "ax4 = axes[1, 0]\n",
    "try:\n",
    "    fake_text_filtered = fake_data['text_length'].dropna()\n",
    "    true_text_filtered = true_data['text_length'].dropna()\n",
    "\n",
    "    # Filter outliers for better visualization\n",
    "    fake_text_filtered = fake_text_filtered[fake_text_filtered <= 10000]\n",
    "    true_text_filtered = true_text_filtered[true_text_filtered <= 10000]\n",
    "\n",
    "    data_to_plot = [fake_text_filtered.values, true_text_filtered.values]\n",
    "    bp = ax4.boxplot(data_to_plot, labels=['Fake News', 'True News'], patch_artist=True)\n",
    "    bp['boxes'][0].set_facecolor('#ff6b6b')\n",
    "    bp['boxes'][1].set_facecolor('#4ecdc4')\n",
    "    ax4.set_ylabel('Text Length (characters)')\n",
    "    ax4.set_title('Text Length Box Plot', fontweight='bold')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in box plot: {e}\")\n",
    "    ax4.text(0.5, 0.5, 'Text Length Box Plot\\n(Error in data)',\n",
    "             ha='center', va='center', transform=ax4.transAxes)\n",
    "\n",
    "# 5. Subject Distribution - Super safe version\n",
    "ax5 = axes[1, 1]\n",
    "try:\n",
    "    # Simple bar chart of subject distribution\n",
    "    subject_counts = df_features['subject'].value_counts()\n",
    "    x_pos = range(len(subject_counts))\n",
    "\n",
    "    bars = ax5.bar(x_pos, subject_counts.values, color='skyblue')\n",
    "    ax5.set_title('Subject Distribution', fontweight='bold')\n",
    "    ax5.set_xlabel('Subject Category')\n",
    "    ax5.set_ylabel('Count')\n",
    "    ax5.set_xticks(x_pos)\n",
    "    ax5.set_xticklabels(subject_counts.index, rotation=45, ha='right')\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax5.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}', ha='center', va='bottom')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in subject plot: {e}\")\n",
    "    ax5.text(0.5, 0.5, 'Subject Distribution\\n(Error in data)',\n",
    "             ha='center', va='center', transform=ax5.transAxes)\n",
    "\n",
    "# 6. Word Count Distribution - Super safe version\n",
    "ax6 = axes[1, 2]\n",
    "try:\n",
    "    fake_word_count = fake_data['text_word_count'].dropna().values.flatten()\n",
    "    true_word_count = true_data['text_word_count'].dropna().values.flatten()\n",
    "\n",
    "    # Filter extreme values\n",
    "    fake_word_count = fake_word_count[fake_word_count < 3000]\n",
    "    true_word_count = true_word_count[true_word_count < 3000]\n",
    "\n",
    "    ax6.hist(fake_word_count, bins=50, alpha=0.7, density=True, label='Fake News', color='red')\n",
    "    ax6.hist(true_word_count, bins=50, alpha=0.7, density=True, label='True News', color='blue')\n",
    "    ax6.set_xlabel('Word Count')\n",
    "    ax6.set_ylabel('Density')\n",
    "    ax6.set_title('Word Count Distribution', fontweight='bold')\n",
    "    ax6.legend()\n",
    "    ax6.set_xlim(0, 2000)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in word count plot: {e}\")\n",
    "    ax6.text(0.5, 0.5, 'Word Count Distribution\\n(Error in data)',\n",
    "             ha='center', va='center', transform=ax6.transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print insights - Safe version\n",
    "try:\n",
    "    print(\"=== KEY DISTRIBUTION INSIGHTS ===\")\n",
    "    fake_text_mean = fake_data['text_length'].mean()\n",
    "    true_text_mean = true_data['text_length'].mean()\n",
    "    fake_title_mean = fake_data['title_length'].mean()\n",
    "    true_title_mean = true_data['title_length'].mean()\n",
    "    fake_word_mean = fake_data['text_word_count'].mean()\n",
    "    true_word_mean = true_data['text_word_count'].mean()\n",
    "\n",
    "    print(f\"Average text length - Fake: {fake_text_mean:.0f}, True: {true_text_mean:.0f}\")\n",
    "    print(f\"Average title length - Fake: {fake_title_mean:.1f}, True: {true_title_mean:.1f}\")\n",
    "    print(f\"Average word count - Fake: {fake_word_mean:.0f}, True: {true_word_mean:.0f}\")\n",
    "\n",
    "    print(f\"\\nData Quality Check:\")\n",
    "    print(f\"Fake articles count: {len(fake_data)}\")\n",
    "    print(f\"True articles count: {len(true_data)}\")\n",
    "    print(f\"Total articles: {len(df_features)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in printing insights: {e}\")\n",
    "    print(\"Please check your data structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmYy75aMtdPQ"
   },
   "source": [
    "## 5. Correlation Analysis and Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17563,
     "status": "aborted",
     "timestamp": 1764462788022,
     "user": {
      "displayName": "Ledja Halltari",
      "userId": "02609488241572809833"
     },
     "user_tz": 480
    },
    "id": "tpPU7kUutdPQ"
   },
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "print(\"=== CORRELATION ANALYSIS ===\")\n",
    "\n",
    "# Select features for correlation analysis\n",
    "correlation_features = [\n",
    "    'label', 'text_length', 'title_length', 'text_word_count', 'title_word_count',\n",
    "    'text_caps_ratio', 'title_caps_ratio', 'text_exclamation_ratio',\n",
    "    'title_exclamation_ratio', 'text_question_ratio', 'title_question_ratio'\n",
    "]\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df_features[correlation_features].corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Mask upper triangle\n",
    "\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0,\n",
    "            square=True, fmt='.3f', cbar_kws={'shrink': 0.8},\n",
    "            mask=mask)\n",
    "plt.title('Feature Correlation Matrix\\n(Focus on relationship with label)', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature-target correlations\n",
    "target_correlations = corr_matrix['label'].drop('label').sort_values(key=abs, ascending=False)\n",
    "print(\"\\nFeature-Target Correlations (sorted by absolute value):\")\n",
    "for feature, corr in target_correlations.items():\n",
    "    print(f\"{feature:<25}: {corr:6.3f}\")\n",
    "\n",
    "# Identify strongest predictors\n",
    "strong_predictors = target_correlations[abs(target_correlations) > 0.1]\n",
    "print(f\"\\nStrong predictors (|correlation| > 0.1): {len(strong_predictors)}\")\n",
    "for feature, corr in strong_predictors.items():\n",
    "    direction = \"positively\" if corr > 0 else \"negatively\"\n",
    "    print(f\"  {feature} is {direction} correlated with authenticity (r={corr:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYSDK3YEtdPQ"
   },
   "source": [
    "## 6. Outlier Analysis and Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17563,
     "status": "aborted",
     "timestamp": 1764462788023,
     "user": {
      "displayName": "Ledja Halltari",
      "userId": "02609488241572809833"
     },
     "user_tz": 480
    },
    "id": "wu2H2mgZtdPR"
   },
   "outputs": [],
   "source": [
    "\n",
    "# First, check for and fix duplicate columns\n",
    "print(\"Checking for duplicate columns...\")\n",
    "print(f\"DataFrame shape: {df_features.shape}\")\n",
    "print(f\"Number of unique column names: {df_features.columns.nunique()}\")\n",
    "print(f\"Total number of columns: {len(df_features.columns)}\")\n",
    "\n",
    "# Check for duplicate columns\n",
    "duplicate_cols = df_features.columns[df_features.columns.duplicated()].tolist()\n",
    "if duplicate_cols:\n",
    "    print(\"-  Duplicate column names detected!\")\n",
    "    print(\"Duplicates:\", duplicate_cols)\n",
    "\n",
    "    # Fix duplicate columns by removing duplicates (keeps first occurrence)\n",
    "    print(\"ðŸ”§ Fixing duplicate columns...\")\n",
    "    df_features = df_features.loc[:, ~df_features.columns.duplicated()]\n",
    "    print(\"Fixed. New shape:\", df_features.shape)\n",
    "else:\n",
    "    print(\"- No duplicate columns found\")\n",
    "\n",
    "# Function to detect outliers using 99th percentile method\n",
    "def detect_outliers_percentile(data, feature, lower_percentile=1, upper_percentile=99):\n",
    "    lower_bound = data[feature].quantile(lower_percentile / 100)\n",
    "    upper_bound = data[feature].quantile(upper_percentile / 100)\n",
    "\n",
    "    outliers = data[(data[feature] < lower_bound) | (data[feature] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Function to detect only upper outliers (for features where low values aren't concerning)\n",
    "def detect_upper_outliers_percentile(data, feature, upper_percentile=99):\n",
    "    upper_bound = data[feature].quantile(upper_percentile / 100)\n",
    "    outliers = data[data[feature] > upper_bound]\n",
    "    return outliers, upper_bound\n",
    "\n",
    "# Analyze outliers for key features\n",
    "outlier_features = ['text_length', 'title_length']\n",
    "\n",
    "\n",
    "# Comprehensive outlier analysis with multiple percentile thresholds\n",
    "percentile_thresholds = [95, 99, 99.5, 99.9]\n",
    "print(\"\\n=== MULTI-THRESHOLD OUTLIER ANALYSIS ===\")\n",
    "\n",
    "for threshold in percentile_thresholds:\n",
    "    print(f\"\\n--- {threshold}th Percentile Outliers ---\")\n",
    "    outlier_summary = []\n",
    "\n",
    "    for feature in outlier_features:\n",
    "        # For length features, only look at upper outliers (unusually long)\n",
    "        outliers, upper_bound = detect_upper_outliers_percentile(df_features, feature, threshold)\n",
    "        lower_bound = None\n",
    "\n",
    "        fake_outliers = len(outliers[outliers['label'] == 0])\n",
    "        true_outliers = len(outliers[outliers['label'] == 1])\n",
    "\n",
    "        outlier_summary.append({\n",
    "            'Feature': feature,\n",
    "            'Total_Outliers': len(outliers),\n",
    "            'Fake_Outliers': fake_outliers,\n",
    "            'True_Outliers': true_outliers,\n",
    "            'Outlier_Percentage': len(outliers) / len(df_features) * 100,\n",
    "            'Lower_Bound': lower_bound,\n",
    "            'Upper_Bound': upper_bound,\n",
    "            'Fake_Rate_in_Outliers': fake_outliers / len(outliers) * 100 if len(outliers) > 0 else 0\n",
    "        })\n",
    "\n",
    "    outlier_df = pd.DataFrame(outlier_summary)\n",
    "    print(outlier_df.round(3))\n",
    "\n",
    "# Detailed analysis using 99th percentile\n",
    "print(\"\\n=== DETAILED 99th PERCENTILE ANALYSIS ===\")\n",
    "outlier_summary_99 = []\n",
    "\n",
    "for feature in outlier_features:\n",
    "    # Get feature statistics\n",
    "    feature_stats = {\n",
    "        'mean': df_features[feature].mean(),\n",
    "        'median': df_features[feature].median(),\n",
    "        'std': df_features[feature].std(),\n",
    "        'min': df_features[feature].min(),\n",
    "        'max': df_features[feature].max(),\n",
    "        '95th': df_features[feature].quantile(0.95),\n",
    "        '99th': df_features[feature].quantile(0.99),\n",
    "        '99.9th': df_features[feature].quantile(0.999)\n",
    "    }\n",
    "\n",
    "    # Detect 99th percentile outliers (upper outliers only for length features)\n",
    "    outliers, upper_bound = detect_upper_outliers_percentile(df_features, feature, 99)\n",
    "    lower_bound = None\n",
    "\n",
    "    fake_outliers = len(outliers[outliers['label'] == 0])\n",
    "    true_outliers = len(outliers[outliers['label'] == 1])\n",
    "\n",
    "    print(f\"\\n--- {feature.replace('_', ' ').title()} Analysis ---\")\n",
    "    print(f\"Statistics: Mean={feature_stats['mean']:.2f}, Median={feature_stats['median']:.2f}, Std={feature_stats['std']:.2f}\")\n",
    "    print(f\"Percentiles: 95th={feature_stats['95th']:.2f}, 99th={feature_stats['99th']:.2f}, 99.9th={feature_stats['99.9th']:.2f}\")\n",
    "    print(f\"99th Percentile Threshold: {upper_bound:.2f}\")\n",
    "    print(f\"Total Outliers: {len(outliers)} ({len(outliers)/len(df_features)*100:.2f}%)\")\n",
    "    print(f\"Fake News Outliers: {fake_outliers} ({fake_outliers/len(outliers)*100:.1f}% of outliers)\")\n",
    "    print(f\"True News Outliers: {true_outliers} ({true_outliers/len(outliers)*100:.1f}% of outliers)\")\n",
    "\n",
    "    outlier_summary_99.append({\n",
    "        'Feature': feature,\n",
    "        'Total_Outliers': len(outliers),\n",
    "        'Fake_Outliers': fake_outliers,\n",
    "        'True_Outliers': true_outliers,\n",
    "        'Outlier_Percentage': len(outliers) / len(df_features) * 100,\n",
    "        'Fake_Rate_in_Outliers': fake_outliers / len(outliers) * 100 if len(outliers) > 0 else 0,\n",
    "        'Upper_Threshold': upper_bound,\n",
    "        'Lower_Threshold': lower_bound\n",
    "    })\n",
    "\n",
    "# Visualize outliers with 99th percentile thresholds\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('99th Percentile Outlier Analysis - Box Plots by Class', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, feature in enumerate(outlier_features):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    # Create box plot\n",
    "    fake_data = df_features[df_features['label'] == 0][feature]\n",
    "    true_data = df_features[df_features['label'] == 1][feature]\n",
    "\n",
    "    data_to_plot = [fake_data, true_data]\n",
    "    bp = ax.boxplot(data_to_plot, labels=['Fake News', 'True News'], patch_artist=True)\n",
    "    bp['boxes'][0].set_facecolor('#ff6b6b')\n",
    "    bp['boxes'][1].set_facecolor('#4ecdc4')\n",
    "\n",
    "    # Add 99th percentile line\n",
    "    percentile_99 = df_features[feature].quantile(0.99)\n",
    "    ax.axhline(y=percentile_99, color='red', linestyle='--', linewidth=2, alpha=0.7,\n",
    "               label=f'99th Percentile: {percentile_99:.2f}')\n",
    "\n",
    "    ax.set_title(f'{feature.replace(\"_\", \" \").title()}', fontweight='bold')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extreme value analysis with 99th percentile context\n",
    "print(\"\\n=== EXTREME VALUE ANALYSIS WITH PERCENTILE CONTEXT ===\")\n",
    "for feature in outlier_features:\n",
    "    feature_data = df_features[feature]\n",
    "    percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99, 99.5, 99.9]\n",
    "\n",
    "    print(f\"\\n{feature.replace('_', ' ').title()} Distribution:\")\n",
    "    for p in percentiles:\n",
    "        value = feature_data.quantile(p/100)\n",
    "        print(f\"  {p:5.1f}th percentile: {value:8.2f}\")\n",
    "\n",
    "    print(f\"  Minimum: {feature_data.min():8.2f}\")\n",
    "    print(f\"  Maximum: {feature_data.max():8.2f}\")\n",
    "\n",
    "# Identify most extreme cases\n",
    "print(\"\\n=== MOST EXTREME CASES ===\")\n",
    "extreme_cases = []\n",
    "\n",
    "for feature in outlier_features:\n",
    "    # Get top 10 longest values (since all features are length-based)\n",
    "    top_extreme = df_features.nlargest(10, feature)[['label', feature]]\n",
    "    extreme_type = 'longest'\n",
    "\n",
    "    fake_count = (top_extreme['label'] == 0).sum()\n",
    "    true_count = (top_extreme['label'] == 1).sum()\n",
    "\n",
    "    print(f\"\\nTop 10 {extreme_type} {feature.replace('_', ' ')}:\")\n",
    "    print(f\"  Fake news: {fake_count}/10 ({fake_count/10*100:.1f}%)\")\n",
    "    print(f\"  True news: {true_count}/10 ({true_count/10*100:.1f}%)\")\n",
    "    print(f\"  Range: {top_extreme[feature].min():.2f} - {top_extreme[feature].max():.2f}\")\n",
    "\n",
    "# Summary insights\n",
    "print(\"\\n=== KEY INSIGHTS ===\")\n",
    "outlier_df_99 = pd.DataFrame(outlier_summary_99)\n",
    "print(\"99th Percentile Outlier Summary:\")\n",
    "print(outlier_df_99[['Feature', 'Total_Outliers', 'Outlier_Percentage', 'Fake_Rate_in_Outliers']].round(2))\n",
    "\n",
    "print(\"\\nPattern Analysis:\")\n",
    "for _, row in outlier_df_99.iterrows():\n",
    "    feature = row['Feature']\n",
    "    fake_rate = row['Fake_Rate_in_Outliers']\n",
    "    if fake_rate > 60:\n",
    "        print(f\"! {feature}: Fake news overrepresented in outliers ({fake_rate:.1f}%)\")\n",
    "    elif fake_rate < 40:\n",
    "        print(f\"â„¹âœ“  {feature}: True news overrepresented in outliers ({fake_rate:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"~  {feature}: Balanced representation in outliers ({fake_rate:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmKx_-k-tdPR"
   },
   "source": [
    "## 7. Summary of Key Findings (Will add later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGtzQ-X8tdPR"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
